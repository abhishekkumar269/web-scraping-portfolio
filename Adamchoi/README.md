# Adam Choi Football Match Scraper âš½

## ğŸ“Œ Overview
    This project scrapes stock market data from the **NSE (National Stock Exchange of India)** website using Python.  
    It collects real-time market data, processes it, and stores it in a CSV file for further analysis.

---

## âš™ï¸ Features
    - Scrapes real-time data from the target website.  
    - Exports structured results in **CSV/JSON** format.  
    - Includes detailed logging for transparency and debugging.  
    - Lightweight and simple to configure.  
    - Ready to automate with cron jobs or schedulers.

---

## ğŸš€ How to Run

    1. **Clone this repository (or open this folder):**
       ```bash
       git clone https://github.com/abhishekkumar269/web-scraping-portfolio.git
       cd web-scraping-portfolio/Adamchoi
    
    2. Install dependencies:
        pip install -r requirements.txt
    
    3. Run the scraper:
        python adamchoi_scraper.py
    
    4. Output:
        Scraped data â†’ LaLiga_data.csv
          Logs â†’ log.txt

---

## ğŸ“Š Sample Output

            DATE         TEAM-A RESULT      TEAM-B
    0    27-09-2025       Mallorca  1 - 0      Alaves
    1    24-09-2025         Getafe  1 - 1      Alaves
    2    20-09-2025         Alaves  1 - 2     Sevilla
    3    13-09-2025  Athletic Club  0 - 1      Alaves
    4    30-08-2025         Alaves  1 - 1  Ath Madrid
        

---
## ğŸ“¸ Sample Screenshot

<img width="352" height="523" alt="Screenshot 2025-10-07 at 5 08 54â€¯PM copy" src="https://github.com/user-attachments/assets/5da6a434-76a7-47df-9898-91a1e840bc58" />

---
## ğŸ“‚ Project Structure
      
    Adamchoi/
      â”‚â”€â”€ adamchoi_scraper.py   # Main scraper script
      â”‚â”€â”€ LaLiga_data.csv       # Sample scraped data
      â”‚â”€â”€ log.txt               # Log file for scraping activity
      â”‚â”€â”€ requirements.txt      # Python dependencies
      â”‚â”€â”€ README.md             # Project documentation
---

## ğŸ› ï¸ Tech Stack

      Python 3
      Selenium, BeautifulSoup, Requests  
      CSV (data storage)
      Logging (activity tracking)

---
## âœ¨ Future Improvement

      Automate daily scraping using cron jobs.
      Add data visualization (graphs, charts).
      Store results in a database.

---
ğŸ‘¨â€ğŸ’» Author: Abhishek Kumar

  ğŸ”— Part of https://github.com/abhishekkumar269/web-scraping-portfolio
